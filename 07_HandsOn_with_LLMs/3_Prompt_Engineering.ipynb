{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## üìå What is Prompt Engineering?\n",
        "\n",
        "Prompt Engineering is the practice of crafting inputs (called prompts) that guide large language models (LLMs) like GPT, LLaMA, or Falcon to produce desired and accurate outputs.\n",
        "\n",
        "üí° A well-designed prompt helps:\n",
        "- Improve the quality of the output\n",
        "- Reduce hallucinations\n",
        "- Make the model behave in a specific way (teacher, assistant, coder, etc.)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EoAvaY4Rsk_W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup a simple falcon model fot testing"
      ],
      "metadata": {
        "id": "UHccQStis4Ph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "\n",
        "# Load Falcon model\n",
        "model_id = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
        "\n",
        "# Text generation pipeline\n",
        "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "# Function to generate text\n",
        "def chat_with_model(prompt, max_new_tokens=100):\n",
        "    response = generator(prompt, max_new_tokens=max_new_tokens, do_sample=True, temperature=0.7)\n",
        "    return response[0]['generated_text']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlvWAST0q_EP",
        "outputId": "eb1705d6-9316-4f72-8b7b-3865f3eb8c3d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üéØ Zero-shot Prompting\n",
        "\n",
        "You give the model a task without showing any example. It relies on its general knowledge to respond.\n",
        "\n",
        "**Example:**\n"
      ],
      "metadata": {
        "id": "jpyVnKf2tMg1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Translate this sentence to French: 'I love artificial intelligence.'\"\n",
        "print(chat_with_model(prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CzOIQuitEsJ",
        "outputId": "fa9cd324-b3dd-48f3-ffeb-9d648029e068"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translate this sentence to French: 'I love artificial intelligence.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß™ One-shot Prompting\n",
        "\n",
        "You give **one example** to help the model understand the task better.\n",
        "\n",
        "**Example:**\n"
      ],
      "metadata": {
        "id": "sReS7VlVtdW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Q: What is the capital of France?\n",
        "A: Paris\n",
        "\n",
        "Q: What is the capital of Italy?\n",
        "A:\"\"\"\n",
        "print(chat_with_model(prompt))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHPQ1IM3tQH3",
        "outputId": "04a9a968-c557-46f4-f8ca-940591840bb5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: What is the capital of France?\n",
            "A: Paris\n",
            "\n",
            "Q: What is the capital of Italy?\n",
            "A: Rome\n",
            "\n",
            "Q: What is the capital of the United States?\n",
            "A: Washington D.C.\n",
            "\n",
            "Q: What is the capital of Japan?\n",
            "A: Tokyo\n",
            "\n",
            "Q: What is the capital of South Korea?\n",
            "A: Seoul\n",
            "\n",
            "Q: What is the capital of the United Kingdom?\n",
            "A: London\n",
            "\n",
            "Q: What is the capital of Canada?\n",
            "A: Ottawa\n",
            "\n",
            "Q: What is the capital of Brazil?\n",
            "A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìö Few-shot Prompting\n",
        "\n",
        "You give **multiple examples** to teach the model a pattern before asking your real question.\n",
        "\n",
        "**Example:**\n"
      ],
      "metadata": {
        "id": "-LMS2PjJtps7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Translate English to Spanish:\n",
        "English: Good morning\n",
        "Spanish: Buenos d√≠as\n",
        "\n",
        "English: How are you?\n",
        "Spanish: ¬øC√≥mo est√°s?\n",
        "\n",
        "English: Where is the library?\n",
        "Spanish:\"\"\"\n",
        "print(chat_with_model(prompt))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7Kx5WHkthKZ",
        "outputId": "79d6165e-94d9-456e-84ac-c37e5b69ea07"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translate English to Spanish:\n",
            "English: Good morning\n",
            "Spanish: Buenos d√≠as\n",
            "\n",
            "English: How are you?\n",
            "Spanish: ¬øC√≥mo est√°s?\n",
            "\n",
            "English: Where is the library?\n",
            "Spanish: ¬øC√≥mo est√° el lugar del libro?\n",
            "\n",
            "English: Where is the cafeteria?\n",
            "Spanish: ¬øC√≥mo est√° el cafetero?\n",
            "\n",
            "English: How much is the parking ticket?\n",
            "Spanish: ¬øCu√°nto es el impuesto para la polic√≠a?\n",
            "\n",
            "English: Where is the theater?\n",
            "Spanish: ¬øC√≥mo est√° el teatro?\n",
            "\n",
            "As a reminder, the Spanish\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üßë‚Äçüè´ Role-based Prompting\n",
        "\n",
        "You assign a role to the model (like a tutor, doctor, assistant) to change its behavior.\n",
        "\n",
        "**Example:**\n"
      ],
      "metadata": {
        "id": "b24oQyrxt3S9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"You are a helpful Python tutor. Explain what a 'for loop' does in simple terms.\"\n",
        "print(chat_with_model(prompt))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxvWxW2YtuZH",
        "outputId": "c5eb8ce8-0733-49dc-c4cd-313aa3d825f8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are a helpful Python tutor. Explain what a 'for loop' does in simple terms.\n",
            "- Print the following expressions:\n",
            "- 1 + 1 = 2\n",
            "- (5*10) + (3*20) = 180\n",
            "- (2*50) + (1*100) = 300\n",
            "- (3*250) + (2*350) = 900\n",
            "- (6*2000) + (5*2000) = 36000\n",
            "- (3*400) + (6*500) = 36000\n",
            "- (3*800) + (\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîó Chain-of-Thought Prompting\n",
        "\n",
        "Encourages the model to **show its reasoning** step-by-step before giving the final answer.\n",
        "\n",
        "**Example:**\n"
      ],
      "metadata": {
        "id": "rkNDBhZIuC50"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Question: If there are 3 apples and you take away 2, how many do you have?\n",
        "Let's think step by step:\"\"\"\n",
        "print(chat_with_model(prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kseB2nFWt6tU",
        "outputId": "231b4a65-859b-45a3-f5e7-c1a2311055f6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: If there are 3 apples and you take away 2, how many do you have?\n",
            "Let's think step by step:\n",
            "First, you remove 2 apples from the barrel.\n",
            "Now you have one apple left.\n",
            "How many more apples are left in the barrel?\n",
            "Answer: 3\n",
            "Question: If you have an apple, how many more do you need to eat it?\n",
            "How many apples do you need to eat an apple?\n",
            "Answer: 3\n",
            "Question: If you want to reach a certain place, how do you get there?\n",
            "How do you get to a certain place?\n",
            "Answer:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìù Instruction Prompting\n",
        "\n",
        "Clearly tell the model what to do using task-oriented instructions.\n",
        "\n",
        "**Example:**\n"
      ],
      "metadata": {
        "id": "ccbhjm8auVwu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Summarize the following text in one sentence: Artificial intelligence is the simulation of human intelligence processes by machines.\"\n",
        "print(chat_with_model(prompt))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBhx4xg2uHEB",
        "outputId": "4fc12fab-c1f6-4c4f-be59-93e0711779c2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarize the following text in one sentence: Artificial intelligence is the simulation of human intelligence processes by machines.\n",
            "Read the following text in one sentence: The history of artificial intelligence dates back to the mid-20th century.\n",
            "Match the following statements with a correct answer.\n",
            "A. Artificial intelligence is a branch of computer science that deals with the simulation of human intelligence processes by machines.\n",
            "B. Artificial intelligence is a branch of computer science that deals with the simulation of human intelligence processes by machines.\n",
            "C. Artificial intelligence is a branch of computer science that deals with the simulation of human intelligence processes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt Engineering Tips\n",
        "\n",
        "- Use clear and specific language.\n",
        "- Provide examples if the task is complex.\n",
        "- Use formatting like bullet points or JSON if expecting structured output.\n",
        "- Assign roles (e.g., \"You are an expert data scientist\").\n",
        "- Try multiple styles of prompts for the same task to compare results.\n"
      ],
      "metadata": {
        "id": "SkQekbMCucc_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cQAnBRA8uSWT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}